{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "### gene expression data \n",
    "gpl = np.load('data/microarray/gpl570_expression.npy') #microarray samples - older and shittier\n",
    "refine = np.load('data/RNAseq/filtered_refine.bio_tpm_expression.npy') #RNAseq samples - new technology\n",
    "\n",
    "### age, sex, and other sample metadata for each sample id\n",
    "gpl_labels = pd.read_csv('data/microarray/sample-filtered_manually_annotated_gpl570_age-sex_sample_labels.tsv', sep='\\t', encoding='ISO-8859-1')\n",
    "refine_labels = pd.read_csv('data/RNAseq/sample-filtered_manually_annotated_refine.bio_age-sex_sample_labels.tsv', sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16107, 18478)\n",
      "(14232, 25570)\n",
      "(16107, 8)\n",
      "(14232, 10)\n"
     ]
    }
   ],
   "source": [
    "print(gpl.shape)\n",
    "print(refine.shape)\n",
    "print(gpl_labels.shape)\n",
    "print(refine_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gse</th>\n",
       "      <th>gsm</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>fine_age_group</th>\n",
       "      <th>tissue</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSE11151</td>\n",
       "      <td>GSM281311</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>D014551:Urinary Tract|D014566:Urogenital System</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSE11151</td>\n",
       "      <td>GSM281312</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>D014551:Urinary Tract|D014566:Urogenital System</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSE12621</td>\n",
       "      <td>GSM315989</td>\n",
       "      <td>female</td>\n",
       "      <td>19wk</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>D005123:Eye|D012679:Sense Organs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSE12621</td>\n",
       "      <td>GSM315990</td>\n",
       "      <td>male</td>\n",
       "      <td>19wk</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>D005123:Eye|D012679:Sense Organs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSE12621</td>\n",
       "      <td>GSM315991</td>\n",
       "      <td>female</td>\n",
       "      <td>19wk</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>D005123:Eye|D012679:Sense Organs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gse        gsm     sex   age age_group fine_age_group  \\\n",
       "0  GSE11151  GSM281311  female   NaN     fetus          fetus   \n",
       "1  GSE11151  GSM281312    male   NaN     fetus          fetus   \n",
       "2  GSE12621  GSM315989  female  19wk     fetus          fetus   \n",
       "3  GSE12621  GSM315990    male  19wk     fetus          fetus   \n",
       "4  GSE12621  GSM315991  female  19wk     fetus          fetus   \n",
       "\n",
       "                                            tissue disease  \n",
       "0  D014551:Urinary Tract|D014566:Urogenital System     NaN  \n",
       "1  D014551:Urinary Tract|D014566:Urogenital System     NaN  \n",
       "2                 D005123:Eye|D012679:Sense Organs     NaN  \n",
       "3                 D005123:Eye|D012679:Sense Organs     NaN  \n",
       "4                 D005123:Eye|D012679:Sense Organs     NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpl_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>run</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>fine_age_group</th>\n",
       "      <th>tissue</th>\n",
       "      <th>cells</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERS2615349</td>\n",
       "      <td>ERR2704713</td>\n",
       "      <td>ERP109940</td>\n",
       "      <td>female</td>\n",
       "      <td>12wk</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERS2615350</td>\n",
       "      <td>ERR2704714</td>\n",
       "      <td>ERP109940</td>\n",
       "      <td>male</td>\n",
       "      <td>12wk</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERS2615351</td>\n",
       "      <td>ERR2704715</td>\n",
       "      <td>ERP109940</td>\n",
       "      <td>male</td>\n",
       "      <td>16wk</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ERS2615352</td>\n",
       "      <td>ERR2704716</td>\n",
       "      <td>ERP109940</td>\n",
       "      <td>male</td>\n",
       "      <td>16wk</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERS2615354</td>\n",
       "      <td>ERR2704718</td>\n",
       "      <td>ERP109940</td>\n",
       "      <td>female</td>\n",
       "      <td>9wk</td>\n",
       "      <td>fetus</td>\n",
       "      <td>fetus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample         run experiment     sex   age age_group fine_age_group  \\\n",
       "0  ERS2615349  ERR2704713  ERP109940  female  12wk     fetus          fetus   \n",
       "1  ERS2615350  ERR2704714  ERP109940    male  12wk     fetus          fetus   \n",
       "2  ERS2615351  ERR2704715  ERP109940    male  16wk     fetus          fetus   \n",
       "3  ERS2615352  ERR2704716  ERP109940    male  16wk     fetus          fetus   \n",
       "4  ERS2615354  ERR2704718  ERP109940  female   9wk     fetus          fetus   \n",
       "\n",
       "  tissue cells disease  \n",
       "0    NaN   NaN  normal  \n",
       "1    NaN   NaN  normal  \n",
       "2    NaN   NaN  normal  \n",
       "3    NaN   NaN  normal  \n",
       "4    NaN   NaN  normal  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPL (microarray) Summary:\n",
      "Column 9109 {'mean': 12.480291823213761, 'std': 0.680430943570284, 'min': 4.9842064528086905, 'max': 14.499726539010402}\n",
      "Column 12657 {'mean': 6.745498146112469, 'std': 1.1114288813265727, 'min': 3.82853712334982, 'max': 10.523073465635699}\n",
      "Column 1156 {'mean': 6.045624064282047, 'std': 1.0112465717009151, 'min': 4.13875937013015, 'max': 10.638822530382098}\n",
      "Column 294 {'mean': 5.261984642452963, 'std': 0.812698874230374, 'min': 3.97796353828031, 'max': 11.0528370500697}\n",
      "Column 14144 {'mean': 7.4581728209158795, 'std': 0.8794532278112108, 'min': 3.8241973489885, 'max': 12.081155023257}\n",
      "\n",
      "Refine (RNAseq) Summary:\n",
      "Column 17921 {'mean': 5.63822037064362, 'std': 15.047018918298683, 'min': 0.0, 'max': 465.491334}\n",
      "Column 25477 {'mean': 13.041578083825183, 'std': 46.83858584414753, 'min': 0.0, 'max': 363.195231}\n",
      "Column 12986 {'mean': 32.83946157651771, 'std': 23.208142482865995, 'min': 0.0, 'max': 181.94722099999998}\n",
      "Column 15423 {'mean': 3.8994348126053957, 'std': 40.71258796745168, 'min': 0.0, 'max': 1165.053373}\n",
      "Column 8255 {'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 5 columns\n",
    "gpl_random_cols = np.random.choice(gpl.shape[1], 5, replace=False)\n",
    "refine_random_cols = np.random.choice(refine.shape[1], 5, replace=False)\n",
    "\n",
    "# Compute summary statistics\n",
    "gpl_summary = {f\"Column {col}\": {\n",
    "    \"mean\": np.mean(gpl[:, col]),\n",
    "    \"std\": np.std(gpl[:, col]),\n",
    "    \"min\": np.min(gpl[:, col]),\n",
    "    \"max\": np.max(gpl[:, col])\n",
    "} for col in gpl_random_cols}\n",
    "\n",
    "refine_summary = {f\"Column {col}\": {\n",
    "    \"mean\": np.mean(refine[:, col]),\n",
    "    \"std\": np.std(refine[:, col]),\n",
    "    \"min\": np.min(refine[:, col]),\n",
    "    \"max\": np.max(refine[:, col])\n",
    "} for col in refine_random_cols}\n",
    "\n",
    "# Print the summaries\n",
    "print(\"GPL (microarray) Summary:\")\n",
    "for col, stats in gpl_summary.items():\n",
    "    print(col, stats)\n",
    "\n",
    "print(\"\\nRefine (RNAseq) Summary:\")\n",
    "for col, stats in refine_summary.items():\n",
    "    print(col, stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONLY IF COMBINING RNAseq with microarray --> drop all the genes (columns) that are not shared between gpl and refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16107, 18478)\n",
      "(14232, 18478)\n"
     ]
    }
   ],
   "source": [
    "# # Load gene IDs from both files\n",
    "# gene_ids_common = np.loadtxt('data/microarray/common_Entrez_IDs_gpl570-refine.bio.txt', dtype=str) # this is techincally gpl/microarray. just old name and file mix ups type shit\n",
    "# gene_ids_refine = np.loadtxt('data/RNAseq/refine.bio_geneIDs.txt', dtype=str)\n",
    "\n",
    "# # Find the common gene IDs\n",
    "# common_genes = np.intersect1d(gene_ids_refine, gene_ids_common)\n",
    "\n",
    "# # Identify the columns corresponding to the common genes in both arrays\n",
    "# common_columns_gpl = np.isin(gene_ids_common, common_genes)\n",
    "# common_columns_refine = np.isin(gene_ids_refine, common_genes)\n",
    "\n",
    "# # Filter the original expression data (gpl and refine)\n",
    "# gpl = gpl[:, common_columns_gpl]\n",
    "# refine = refine[:, common_columns_refine]\n",
    "\n",
    "# print(gpl.shape)\n",
    "# print(refine.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### also drop columns that have 0 for mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in gpl with mean and std of 0: []\n",
      "Columns in refine with mean and std of 0: [    6    21    23    29    30    45    52    71    77    79   101   131\n",
      "   152   169   179   216   219   226   231   236   242   248   274   279\n",
      "   280   296   303   317   319   323   333   345   346   363   372   378\n",
      "   383   384   386   394   397   398   402   406   408   409   414   418\n",
      "   419   420   421   429   436   440   459   461   462   463   464   465\n",
      "   466   467   469   470   472   473   474   475   476   478   506   520\n",
      "   521   523   529   541   555   568   569   572   579   582   584   590\n",
      "   600   606   614   615   616   619   624   628   672   757   764   771\n",
      "   822   830   834   845   848   850   858   862   899   933   946   970\n",
      "   971   986  1015  1128  1221  1253  1274  1310  1387  1394  1404  1407\n",
      "  1410  1469  1541  1621  1661  1712  1717  1797  1880  1976  1985  2021\n",
      "  2032  2067  2086  2349  2391  2401  2402  2403  2427  2456  2476  2533\n",
      "  2563  2596  2604  2700  2826  2893  2947  2954  2959  2963  2969  3006\n",
      "  3032  3049  3064  3095  3112  3127  3128  3159  3166  3270  3316  3322\n",
      "  3323  3324  3340  3349  3355  3461  3489  3573  3629  3630  3632  3671\n",
      "  3674  3719  3729  3746  3847  3855  3860  3867  3868  3873  3876  3880\n",
      "  3888  3899  3903  3905  3906  3910  3926  3966  3974  3976  3977  3979\n",
      "  3983  4074  4076  4079  4080  4081  4085  4086  4087  4098  4121  4127\n",
      "  4188  4334  4349  4354  4380  4381  4383  4384  4385  4389  4411  4433\n",
      "  4443  4449  4459  4466  4471  4482  4489  4491  4499  4509  4517  4520\n",
      "  4524  4527  4533  4538  4544  4568  4571  4605  4613  4615  4623  4625\n",
      "  4629  4658  4659  4662  4676  4682  4686  4693  4702  4706  4708  4712\n",
      "  4723  4744  4757  4761  4795  4799  4807  4809  4959  5057  5075  5076\n",
      "  5078  5079  5092  5103  5104  5110  5115  5120  5131  5132  5134  5135\n",
      "  5137  5138  5140  5143  5144  5147  5151  5231  5294  5330  5380  5381\n",
      "  5387  5423  5603  5627  5630  5636  5637  5644  5645  5646  5647  5652\n",
      "  5768  5807  5892  5915  5918  6034  6062  6150  6264  6280  6285  6362\n",
      "  6466  6717  6958  6983  7120  7141  7161  7238  7329  7354  7401  7414\n",
      "  7464  7465  7489  7514  7528  7537  7592  7618  7628  7638  7650  7682\n",
      "  7707  7782  7809  7813  7819  7832  7848  7862  7873  7885  7902  7910\n",
      "  7927  7928  7950  8031  8078  8080  8102  8255  8267  8276  8285  8520\n",
      "  8537  8615  8662  8684  8712  8763  8812  8935  8942  9030  9032  9085\n",
      "  9343  9400  9818  9898  9899  9933  9968  9994 10011 10023 10068 10069\n",
      " 10082 10197 10224 10244 10466 10546 10650 10669 10686 10730 10731 10765\n",
      " 10796 10824 10891 10910 10932 10934 10936 10937 11065 11191 11201 11253\n",
      " 11299 11305 11308 11327 11386 11405 11420 11429 11434 11480 11487 11492\n",
      " 11497 11510 11532 11544 11548 11644 11764 11779 11781 11791 11838 11847\n",
      " 11858 12026 12027 12042 12045 12055 12065 12180 12315 12323 12324 12326\n",
      " 12332 12368 12370 12374 12458 12516 12586 12625 12741 12752 12755 12768\n",
      " 12810 12831 12853 12873 12896 12912 12913 12918 12964 12990 13037 13038\n",
      " 13040 13050 13065 13106 13167 13168 13301 13312 13392 13404 13412 13474\n",
      " 13477 13478 13479 13481 13484 13549 13554 13577 13581 13594 13605 13620\n",
      " 13630 13658 13664 13676 13698 13732 13789 13794 13818 13895 13896 13898\n",
      " 13907 13915 13941 13953 13961 13962 13970 13977 13983 14054 14055 14063\n",
      " 14064 14072 14077 14149 14151 14163 14253 14267 14278 14283 14318 14329\n",
      " 14630 14637 14643 14644 14857 14867 14878 14880 14883 14887 14894 14899\n",
      " 14905 14926 14939 14943 14945 14956 14969 14970 14973 14975 14989 14994\n",
      " 15000 15003 15007 15010 15015 15018 15021 15024 15034 15039 15040 15042\n",
      " 15045 15046 15094 15112 15113 15114 15116 15118 15120 15295 15296 15297\n",
      " 15298 15419 15478 15587 15588 15590 15591 15598 15599 15600 15694 15764\n",
      " 16098 16260 16406 16496 16504 16520 16544 16553 16578 16725 16772 16797\n",
      " 16872 17322 17391 17398 17482 17735 17748 17798 17841 18272 18287 18297\n",
      " 18388 18449 18689 18961 18962 19082 19085 19089 19146 19291 19346 19503\n",
      " 19509 19525 19527 19563 19574 19582 19618 19623 19626 19655 19669 19671\n",
      " 19677 19706 19710 19751 19754 19775 19792 19793 19798 19803 19816 19818\n",
      " 19823 19824 19829 19836 19840 19845 19852 19853 19855 19860 19871 19895\n",
      " 19911 20030 20086 20112 20113 20127 20150 20161 20166 20167 20183 20204\n",
      " 20208 20211 20216 20248 20249 20315 20382 20710 20890 21078 21133 21158\n",
      " 21160 21162 21164 21165 21167 21168 21175 21184 21202 21203 21205 21208\n",
      " 21211 21213 21214 21218 21241 21251 21258 21264 21282 21288 21289 21290\n",
      " 21305 21319 21325 21335 21337 21339 21341 21346 21362 21370 21371 21381\n",
      " 21392 21677 21936 21968 21971 22004 22006 22337 22341 22351 22542 22622\n",
      " 22668 22671 22676 23067 23090 23248 23446 23574 23589 23749 23781 23787\n",
      " 24041 24235 24236 24401 24443 24448 24609 24809 24855 24933 24975 25213]\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# Find columns in gpl where both mean and std are 0\n",
    "zero_mean_std_cols_gpl = np.where((np.mean(gpl, axis=0) == 0) & (np.std(gpl, axis=0) == 0))[0]\n",
    "print(\"Columns in gpl with mean and std of 0:\", zero_mean_std_cols_gpl)\n",
    "\n",
    "# Find columns in refine where both mean and std are 0\n",
    "zero_mean_std_cols_refine = np.where((np.mean(refine, axis=0) == 0) & (np.std(refine, axis=0) == 0))[0]\n",
    "print(\"Columns in refine with mean and std of 0:\", zero_mean_std_cols_refine)\n",
    "\n",
    "print(len(zero_mean_std_cols_refine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of refine: (14232, 24802)\n"
     ]
    }
   ],
   "source": [
    "# Drop em now\n",
    "zero_mean_std_cols_refine = np.where((np.mean(refine, axis=0) == 0) & (np.std(refine, axis=0) == 0))[0]\n",
    "# Drop those columns from refine\n",
    "refine = np.delete(refine, zero_mean_std_cols_refine, axis=1)\n",
    "\n",
    "print(\"New shape of refine:\", refine.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep track of the column (geneID) names in RNAseq by saving these updated columns to new txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('jawn.txt', 'r') as file:\n",
    "with open('data/RNAseq/refine.bio_geneIDs.txt', 'r') as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Remove the gene IDs corresponding to the zero-mean/zero-std columns\n",
    "filtered_gene_ids = [gene_id for i, gene_id in enumerate(lines) if i not in zero_mean_std_cols_refine]\n",
    "\n",
    "# Save the filtered gene IDs to a new file\n",
    "with open('data/RNAseq/UPDATED_refine.bio_geneIDs.txt', 'w') as f:\n",
    "    f.write('\\n'.join(filtered_gene_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now standardize the values . \n",
    "#### gpl (microarray) doesn't have to be standardized because .....\n",
    "#### refine (RNAseq) needs to have arcsin applied to it because ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_normed = np.arcsinh(refine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare what original vs normalized refine dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refine Summary:\n",
      "Column 12209 {'mean': 0.13948403499156828, 'std': 0.4279829262725154, 'min': 0.0, 'max': 27.250778999999998}\n",
      "Column 14141 {'mean': 34.6074455054806, 'std': 234.02659167854918, 'min': 0.0, 'max': 9169.115392999998}\n",
      "Column 14026 {'mean': 5.59550573826588, 'std': 28.52327499730319, 'min': 0.0, 'max': 778.647848}\n",
      "Column 7322 {'mean': 0.3206617674957841, 'std': 1.007074318443456, 'min': 0.0, 'max': 65.752484}\n",
      "Column 461 {'mean': 2.118664170460933, 'std': 8.625259581743737, 'min': 0.0, 'max': 301.384425}\n",
      "\n",
      "Refine Normed Summary:\n",
      "Column 12209 {'mean': 0.12214490065543492, 'std': 0.25358664634737155, 'min': 0.0, 'max': 3.998565771290158}\n",
      "Column 14141 {'mean': 2.193795391889703, 'std': 1.9430971229562706, 'min': 0.0, 'max': 9.816743276628058}\n",
      "Column 14026 {'mean': 0.9002072176162816, 'std': 1.2994130597675237, 'min': 0.0, 'max': 7.35070648008168}\n",
      "Column 7322 {'mean': 0.25239339809026917, 'std': 0.3768150922492418, 'min': 0.0, 'max': 4.8791024503620735}\n",
      "Column 461 {'mean': 0.836458407179777, 'std': 0.9034707959401725, 'min': 0.0, 'max': 6.401536542208143}\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 5 columns\n",
    "random_cols = np.random.choice(refine.shape[1], 5, replace=False)\n",
    "\n",
    "# Compute summary statistics\n",
    "refine_summary = {f\"Column {col}\": {\n",
    "    \"mean\": np.mean(refine[:, col]),\n",
    "    \"std\": np.std(refine[:, col]),\n",
    "    \"min\": np.min(refine[:, col]),\n",
    "    \"max\": np.max(refine[:, col])\n",
    "} for col in random_cols}\n",
    "\n",
    "refine_normed_summary = {f\"Column {col}\": {\n",
    "    \"mean\": np.mean(refine_normed[:, col]),\n",
    "    \"std\": np.std(refine_normed[:, col]),\n",
    "    \"min\": np.min(refine_normed[:, col]),\n",
    "    \"max\": np.max(refine_normed[:, col])\n",
    "} for col in random_cols}\n",
    "\n",
    "# Print the summaries\n",
    "print(\"Refine Summary:\")\n",
    "for col, stats in refine_summary.items():\n",
    "    print(col, stats)\n",
    "\n",
    "print(\"\\nRefine Normed Summary:\")\n",
    "for col, stats in refine_normed_summary.items():\n",
    "    print(col, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create the response variable, binned age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16107\n",
      "16107\n",
      "16057\n",
      "16057\n"
     ]
    }
   ],
   "source": [
    "# first drop the rows with N/A age\n",
    "gpl_labels2 = gpl_labels.dropna(subset=['age'])\n",
    "gpl2 = gpl[gpl_labels2.index]\n",
    "\n",
    "print(len(gpl_labels))\n",
    "print(len(gpl))\n",
    "print(len(gpl_labels2))\n",
    "print(len(gpl2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14232\n",
      "14232\n",
      "14206\n",
      "14206\n"
     ]
    }
   ],
   "source": [
    "# same with refine\n",
    "refine_labels2 = refine_labels.dropna(subset=['age'])\n",
    "refine_normed2 = refine_normed[refine_labels2.index]\n",
    "\n",
    "print(len(refine_labels))\n",
    "print(len(refine_normed))\n",
    "print(len(refine_labels2))\n",
    "print(len(refine_normed2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the binned age category\n",
    "gpl_labels2 = gpl_labels2.copy()\n",
    "gpl_labels2['age_in_years'] = gpl_labels2['age'].apply(\n",
    "    lambda age: \n",
    "    float(age.replace('wk', '').strip()) * 7 / 365 if isinstance(age, str) and 'wk' in age \n",
    "    else (float(age) if isinstance(age, (int, float)) or (isinstance(age, str) and age.replace('.', '', 1).isdigit()) #1 argument ensures that only one occurrence of . is removed\n",
    "    else None)\n",
    ")\n",
    "\n",
    "bins = [0, 2, 8, 12, 20, 35, 45, 60, 70, 80, float('inf')]\n",
    "labels = ['[0–2]', '(2–8]', '(8–12]', '(12–20]', '(20–35]', '(35–45]', '(45–60]', '(60–70]', '(70–80]', '> 80']\n",
    "\n",
    "gpl_labels2['age_bin'] = pd.cut(gpl_labels2['age_in_years'], bins=bins, labels=labels, right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j7/ddlht6kj6dj0_8kvm5tg6q040000gn/T/ipykernel_16194/1183150525.py:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  refine_labels2['age_in_years'] = refine_labels2['age_in_years'].fillna(refine_labels2['age'].replace(age_mapping))\n"
     ]
    }
   ],
   "source": [
    "# same for refine\n",
    "refine_labels2 = refine_labels2.copy()\n",
    "refine_labels2['age_in_years'] = refine_labels2['age'].apply(\n",
    "    lambda age: \n",
    "    float(age.replace('wk', '').strip()) * 7 / 365 if isinstance(age, str) and 'wk' in age \n",
    "    else (float(age) if isinstance(age, (int, float)) or (isinstance(age, str) and age.replace('.', '', 1).isdigit()) #1 argument ensures that only one occurrence of . is removed\n",
    "    else None)\n",
    ")\n",
    "\n",
    "# Map nonstandard age categories to approximate values in years\n",
    "age_mapping = {\n",
    "    'Carnegie Stage 23': 0.16,  # ~ 8 weeks (~0.16 years)\n",
    "    'Carnegie Stage 22': 0.15,  # ~ 7.5 weeks\n",
    "    'Carnegie Stage 21': 0.14,  # ~ 7 weeks\n",
    "    'Carnegie Stage21': 0.14,  # account for the typo\n",
    "    'Carnegie Stage 20': 0.13,  # ~ 6.5 weeks\n",
    "    'Carnegie Stage 19': 0.12,  # ~ 6 weeks\n",
    "    'Carnegie Stage 18': 0.11,  # ~ 5.5 weeks\n",
    "    'Carnegie Stage 17': 0.10,  # ~ 5 weeks\n",
    "    'Carnegie Stage 16': 0.09,  # ~ 4.5 weeks\n",
    "    'Carnegie Stage 15': 0.08,  # ~ 4 weeks\n",
    "    'Carnegie Stage 14': 0.07,  # ~ 3.5 weeks\n",
    "    'Carnegie Stage 13': 0.06,  # ~ 3 weeks\n",
    "    'fetus': 0.17,              # ~ 9 weeks\n",
    "    '9 post conception weeks': 0.17,\n",
    "    '10 post conception weeks': 0.19,\n",
    "    '11 post conception weeks': 0.21,\n",
    "    '12 post conception weeks': 0.23,\n",
    "    '13 post conception weeks': 0.25,\n",
    "    '14 post conception weeks': 0.27,\n",
    "    '15 post conception weeks': 0.29,\n",
    "    '16 post conception weeks': 0.31,\n",
    "    '17 post conception weeks': 0.33,\n",
    "    '19 post conception weeks': 0.37,\n",
    "    '20 post conception weeks': 0.39,\n",
    "    'Late 8 post conception weeks': 0.15,\n",
    "    '0days': 0.0,               # Newborn\n",
    "    '1days': 0.0027,            # 1 day old (approx. years)\n",
    "    '3days': 0.008,             # 3 days old\n",
    "    '7days': 0.02,              # 7 days old\n",
    "    '18-24': 21,                # Midpoint of range\n",
    "    '25-30': 27.5,\n",
    "    '31-36': 33.5,\n",
    "    '37-42': 39.5,\n",
    "    '43-50': 46.5,\n",
    "    '51-60': 55.5,\n",
    "    '< 1': 0.5                  # Less than 1 year old\n",
    "}\n",
    "\n",
    "# Fill nonstandard ages with mapped values\n",
    "refine_labels2['age_in_years'] = refine_labels2['age_in_years'].fillna(refine_labels2['age'].replace(age_mapping))\n",
    "\n",
    "bins = [0, 2, 8, 12, 20, 35, 45, 60, 70, 80, float('inf')]\n",
    "labels = ['[0–2]', '(2–8]', '(8–12]', '(12–20]', '(20–35]', '(35–45]', '(45–60]', '(60–70]', '(70–80]', '> 80']\n",
    "\n",
    "refine_labels2['age_bin'] = pd.cut(refine_labels2['age_in_years'], bins=bins, labels=labels, right=True, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the age_bin column to categorical codes (integer labels)\n",
    "gpl_labels2['age_bin_label'] = pd.Categorical(gpl_labels2['age_bin']).codes\n",
    "refine_labels2['age_bin_label'] = pd.Categorical(refine_labels2['age_bin']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_bin_label\n",
       "6    4420\n",
       "7    2910\n",
       "5    2058\n",
       "4    2007\n",
       "8    1817\n",
       "3     686\n",
       "9     627\n",
       "1     588\n",
       "0     500\n",
       "2     444\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpl_labels2['age_bin_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_bin_label\n",
       "6    2711\n",
       "3    2157\n",
       "4    1867\n",
       "7    1554\n",
       "5    1404\n",
       "0    1243\n",
       "2    1098\n",
       "8     929\n",
       "1     760\n",
       "9     483\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_labels2['age_bin_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14206\n",
      "14206\n",
      "\n",
      "16057\n",
      "16057\n"
     ]
    }
   ],
   "source": [
    "print(len(refine_labels2))\n",
    "print(len(refine_normed2))\n",
    "print()\n",
    "print(len(gpl_labels2))\n",
    "print(len(gpl2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also make a dataset that was not arcsin transformed, just to check its performance in models vs the normalized datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "refine2 = refine[refine_labels2.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14206\n",
      "14206\n"
     ]
    }
   ],
   "source": [
    "print(len(refine2))\n",
    "print(len(refine_labels2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from coral_pytorch.losses import corn_loss\n",
    "from coral_pytorch.dataset import corn_label_from_logits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% train and 20% test\n",
    "labels = refine_labels2['age_bin_label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    refine2, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## \"after applyin arcsin this doesnt matter\" - arjun\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneExpressionDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_units[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[1], num_classes - 1)  # CORN reduces classes by 1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = X_train.shape[1]\n",
    "HIDDEN_UNITS = [64, 32]\n",
    "NUM_CLASSES = 10  # 10 age bins\n",
    "\n",
    "model = MLP(INPUT_SIZE, HIDDEN_UNITS, NUM_CLASSES)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataset = GeneExpressionDataset(X_train, y_train)\n",
    "test_dataset = GeneExpressionDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = corn_loss(outputs, batch_labels, num_classes=NUM_CLASSES)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_features.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "model.eval()\n",
    "total_mae = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        preds = corn_label_from_logits(outputs)\n",
    "        mae = torch.mean(torch.abs(preds - batch_labels.float()))\n",
    "        total_mae += mae.item() * batch_features.size(0)\n",
    "\n",
    "test_mae = total_mae / len(test_loader.dataset)\n",
    "print(f'Test MAE: {test_mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refine (RNAseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE of arcsin with scaler: 0.7241, 0.6780, 0.7220\n",
    "#### MAE of arcsin without scaler: 0.7942, 0.9078, 0.7829\n",
    "#### MAE of raw with scaler: 0.7270, 0.6844, 0.7009\n",
    "#### MAE of raw without scaler: 1.0271, 0.9799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpl (microarray)\n",
    "\n",
    "#### MAE of raw with scaler 1.4044, 1.3615\n",
    "#### MAE of raw without scaler 1.4801, 1.4903"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold CV CORN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/20, Loss: 0.3182\n",
      "Epoch 2/20, Loss: 0.2157\n",
      "Epoch 3/20, Loss: 0.1873\n",
      "Epoch 4/20, Loss: 0.1683\n",
      "Epoch 5/20, Loss: 0.1565\n",
      "Epoch 6/20, Loss: 0.1495\n",
      "Epoch 7/20, Loss: 0.1380\n",
      "Epoch 8/20, Loss: 0.1327\n",
      "Epoch 9/20, Loss: 0.1252\n",
      "Epoch 10/20, Loss: 0.1209\n",
      "Epoch 11/20, Loss: 0.1160\n",
      "Epoch 12/20, Loss: 0.1103\n",
      "Epoch 13/20, Loss: 0.1071\n",
      "Epoch 14/20, Loss: 0.0997\n",
      "Epoch 15/20, Loss: 0.0999\n",
      "Epoch 16/20, Loss: 0.0923\n",
      "Epoch 17/20, Loss: 0.0906\n",
      "Epoch 18/20, Loss: 0.0888\n",
      "Epoch 19/20, Loss: 0.0844\n",
      "Epoch 20/20, Loss: 0.0817\n",
      "Test MAE for fold 1: 0.6882\n",
      "Fold 2\n",
      "Epoch 1/20, Loss: 0.3293\n",
      "Epoch 2/20, Loss: 0.2133\n",
      "Epoch 3/20, Loss: 0.1832\n",
      "Epoch 4/20, Loss: 0.1667\n",
      "Epoch 5/20, Loss: 0.1542\n",
      "Epoch 6/20, Loss: 0.1453\n",
      "Epoch 7/20, Loss: 0.1400\n",
      "Epoch 8/20, Loss: 0.1308\n",
      "Epoch 9/20, Loss: 0.1239\n",
      "Epoch 10/20, Loss: 0.1177\n",
      "Epoch 11/20, Loss: 0.1132\n",
      "Epoch 12/20, Loss: 0.1125\n",
      "Epoch 13/20, Loss: 0.1064\n",
      "Epoch 14/20, Loss: 0.1019\n",
      "Epoch 15/20, Loss: 0.1005\n",
      "Epoch 16/20, Loss: 0.0934\n",
      "Epoch 17/20, Loss: 0.0898\n",
      "Epoch 18/20, Loss: 0.0911\n",
      "Epoch 19/20, Loss: 0.0856\n",
      "Epoch 20/20, Loss: 0.0858\n",
      "Test MAE for fold 2: 0.7008\n",
      "Fold 3\n",
      "Epoch 1/20, Loss: 0.3206\n",
      "Epoch 2/20, Loss: 0.2148\n",
      "Epoch 3/20, Loss: 0.1853\n",
      "Epoch 4/20, Loss: 0.1710\n",
      "Epoch 5/20, Loss: 0.1555\n",
      "Epoch 6/20, Loss: 0.1448\n",
      "Epoch 7/20, Loss: 0.1360\n",
      "Epoch 8/20, Loss: 0.1326\n",
      "Epoch 9/20, Loss: 0.1222\n",
      "Epoch 10/20, Loss: 0.1181\n",
      "Epoch 11/20, Loss: 0.1174\n",
      "Epoch 12/20, Loss: 0.1070\n",
      "Epoch 13/20, Loss: 0.1049\n",
      "Epoch 14/20, Loss: 0.0985\n",
      "Epoch 15/20, Loss: 0.0954\n",
      "Epoch 16/20, Loss: 0.0949\n",
      "Epoch 17/20, Loss: 0.0888\n",
      "Epoch 18/20, Loss: 0.0848\n",
      "Epoch 19/20, Loss: 0.0837\n",
      "Epoch 20/20, Loss: 0.0814\n",
      "Test MAE for fold 3: 0.7557\n",
      "Fold 4\n",
      "Epoch 1/20, Loss: 0.3198\n",
      "Epoch 2/20, Loss: 0.2157\n",
      "Epoch 3/20, Loss: 0.1857\n",
      "Epoch 4/20, Loss: 0.1708\n",
      "Epoch 5/20, Loss: 0.1582\n",
      "Epoch 6/20, Loss: 0.1480\n",
      "Epoch 7/20, Loss: 0.1365\n",
      "Epoch 8/20, Loss: 0.1303\n",
      "Epoch 9/20, Loss: 0.1296\n",
      "Epoch 10/20, Loss: 0.1222\n",
      "Epoch 11/20, Loss: 0.1198\n",
      "Epoch 12/20, Loss: 0.1132\n",
      "Epoch 13/20, Loss: 0.1074\n",
      "Epoch 14/20, Loss: 0.1037\n",
      "Epoch 15/20, Loss: 0.1000\n",
      "Epoch 16/20, Loss: 0.0957\n",
      "Epoch 17/20, Loss: 0.0965\n",
      "Epoch 18/20, Loss: 0.0942\n",
      "Epoch 19/20, Loss: 0.0874\n",
      "Epoch 20/20, Loss: 0.0852\n",
      "Test MAE for fold 4: 0.6990\n",
      "Fold 5\n",
      "Epoch 1/20, Loss: 0.3354\n",
      "Epoch 2/20, Loss: 0.2177\n",
      "Epoch 3/20, Loss: 0.1888\n",
      "Epoch 4/20, Loss: 0.1731\n",
      "Epoch 5/20, Loss: 0.1551\n",
      "Epoch 6/20, Loss: 0.1458\n",
      "Epoch 7/20, Loss: 0.1431\n",
      "Epoch 8/20, Loss: 0.1349\n",
      "Epoch 9/20, Loss: 0.1261\n",
      "Epoch 10/20, Loss: 0.1215\n",
      "Epoch 11/20, Loss: 0.1197\n",
      "Epoch 12/20, Loss: 0.1109\n",
      "Epoch 13/20, Loss: 0.1053\n",
      "Epoch 14/20, Loss: 0.1025\n",
      "Epoch 15/20, Loss: 0.0976\n",
      "Epoch 16/20, Loss: 0.0975\n",
      "Epoch 17/20, Loss: 0.0958\n",
      "Epoch 18/20, Loss: 0.0912\n",
      "Epoch 19/20, Loss: 0.0895\n",
      "Epoch 20/20, Loss: 0.0851\n",
      "Test MAE for fold 5: 0.7145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fold_data.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib  # To save the indices and MAEs to a file\n",
    "\n",
    "INPUT_SIZE = refine2.shape[1]  # Use refine2 for input size\n",
    "HIDDEN_UNITS = [64, 32]\n",
    "NUM_CLASSES = 10  # 10 age bins\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "labels = refine_labels2['age_bin_label'].values\n",
    "\n",
    "# Save indices and MAE for reproducibility\n",
    "fold_indices = {'train': [], 'test': []}\n",
    "fold_mae = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(refine2, labels)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Save train and test indices for this fold\n",
    "    fold_indices['train'].append(train_idx)\n",
    "    fold_indices['test'].append(test_idx)\n",
    "    \n",
    "    # Create train and test sets using numpy array slicing\n",
    "    X_train, X_test = refine2[train_idx], refine2[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Reinitialize the model for each fold\n",
    "    model = MLP(INPUT_SIZE, HIDDEN_UNITS, NUM_CLASSES)\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Reinitialize optimizer for each fold\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Define datasets and dataloaders\n",
    "    train_dataset = GeneExpressionDataset(X_train, y_train)\n",
    "    test_dataset = GeneExpressionDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = corn_loss(outputs, batch_labels, num_classes=NUM_CLASSES)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * batch_features.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    total_mae = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_labels in test_loader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "            outputs = model(batch_features)\n",
    "            preds = corn_label_from_logits(outputs)\n",
    "            mae = torch.mean(torch.abs(preds - batch_labels.float()))\n",
    "            total_mae += mae.item() * batch_features.size(0)\n",
    "\n",
    "    test_mae = total_mae / len(test_loader.dataset)\n",
    "    print(f'Test MAE for fold {fold + 1}: {test_mae:.4f}')\n",
    "    \n",
    "    # Save the trained model for this fold\n",
    "    torch.save(model.state_dict(), f'model_fold_{fold + 1}.pth')\n",
    "    \n",
    "    # Save the MAE for this fold\n",
    "    fold_mae.append(test_mae)\n",
    "    \n",
    "# Save the indices and MAEs to a file for reproducibility\n",
    "joblib.dump({'indices': fold_indices, 'mae': fold_mae}, 'fold_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance for each age bin - is it better for certain age bins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_bin\n",
       "(45–60]    2711\n",
       "(12–20]    2157\n",
       "(20–35]    1867\n",
       "(60–70]    1554\n",
       "(35–45]    1404\n",
       "[0–2]      1243\n",
       "(8–12]     1098\n",
       "(70–80]     929\n",
       "(2–8]       760\n",
       "> 80        483\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_labels2['age_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for label 0: 1.0829\n",
      "MAE for label 1: 0.7539\n",
      "MAE for label 2: 0.6630\n",
      "MAE for label 3: 0.5614\n",
      "MAE for label 4: 0.7568\n",
      "MAE for label 5: 0.6282\n",
      "MAE for label 6: 0.4921\n",
      "MAE for label 7: 0.7117\n",
      "MAE for label 8: 1.0032\n",
      "MAE for label 9: 1.0414\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Define the response variable (target variable)\n",
    "unique_age_bin_labels = np.unique(refine_labels2['age_bin_label'].values)\n",
    "\n",
    "# Initialize a dictionary to hold the sum of absolute errors and counts for each label\n",
    "error_sums = {label: 0 for label in unique_age_bin_labels}\n",
    "counts = {label: 0 for label in unique_age_bin_labels}\n",
    "\n",
    "# Loop through each saved model (for each fold)\n",
    "for fold in range(1, 6):  # Assuming 5-fold models are saved\n",
    "    # Load the saved model for this fold\n",
    "    model = MLP(INPUT_SIZE, HIDDEN_UNITS, NUM_CLASSES)\n",
    "    model.load_state_dict(torch.load(f'model_fold_{fold}.pth'))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Load the corresponding test set indices\n",
    "    fold_data = joblib.load('fold_data.pkl')\n",
    "    test_idx = fold_data['indices']['test'][fold - 1]  # Get the test indices for this fold\n",
    "    X_test = refine2[test_idx]  # Get the test features\n",
    "    y_test = labels[test_idx]   # Get the test labels (age_bin_label)\n",
    "    \n",
    "    # Standardize the test features (using the scaler from the fold)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Perform inference\n",
    "    test_dataset = GeneExpressionDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Accumulate absolute errors for each unique value of the target variable (age_bin_label)\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_labels in test_loader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "            outputs = model(batch_features)\n",
    "            preds = corn_label_from_logits(outputs)\n",
    "\n",
    "            # Calculate absolute errors\n",
    "            abs_errors = torch.abs(preds - batch_labels.float())\n",
    "\n",
    "            # Update error sums and counts for each label in the batch\n",
    "            for i, label in enumerate(batch_labels.cpu().numpy()):\n",
    "                error_sums[label] += abs_errors[i].item()\n",
    "                counts[label] += 1\n",
    "\n",
    "# Calculate MAE for each unique value of the response variable (age_bin_label)\n",
    "mae_per_label = {label: error_sums[label] / counts[label] if counts[label] > 0 else 0 for label in unique_age_bin_labels}\n",
    "\n",
    "# Print MAE for each label\n",
    "for label, mae in mae_per_label.items():\n",
    "    print(f\"MAE for label {label}: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_bin\n",
       "(45–60]    2711\n",
       "(12–20]    2157\n",
       "(20–35]    1867\n",
       "(60–70]    1554\n",
       "(35–45]    1404\n",
       "[0–2]      1243\n",
       "(8–12]     1098\n",
       "(70–80]     929\n",
       "(2–8]       760\n",
       "> 80        483\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_labels2['age_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1243,\n",
       " 1: 760,\n",
       " 2: 1098,\n",
       " 3: 2157,\n",
       " 4: 1867,\n",
       " 5: 1404,\n",
       " 6: 2711,\n",
       " 7: 1554,\n",
       " 8: 929,\n",
       " 9: 483}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 21:34:20.641664: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/davydsadovskyy/krishnanLab/age_sex_proteomic_model/venv_ordinal_neural_network/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.3691 - loss: 2.4832 - val_accuracy: 0.5198 - val_loss: 1.5153\n",
      "Epoch 2/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5789 - loss: 1.2933 - val_accuracy: 0.5638 - val_loss: 1.3785\n",
      "Epoch 3/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6023 - loss: 1.1207 - val_accuracy: 0.5831 - val_loss: 1.2493\n",
      "Epoch 4/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6432 - loss: 1.0054 - val_accuracy: 0.5884 - val_loss: 1.3479\n",
      "Epoch 5/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6638 - loss: 0.9608 - val_accuracy: 0.6139 - val_loss: 1.2630\n",
      "Epoch 6/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6929 - loss: 0.8587 - val_accuracy: 0.6218 - val_loss: 1.3022\n",
      "Epoch 7/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7003 - loss: 0.8371 - val_accuracy: 0.6060 - val_loss: 1.3343\n",
      "Epoch 8/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7223 - loss: 0.7526 - val_accuracy: 0.6165 - val_loss: 1.2758\n",
      "Epoch 9/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7232 - loss: 0.7503 - val_accuracy: 0.6183 - val_loss: 1.3131\n",
      "Epoch 10/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7320 - loss: 0.7183 - val_accuracy: 0.6209 - val_loss: 1.2906\n",
      "Epoch 11/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7421 - loss: 0.6901 - val_accuracy: 0.6227 - val_loss: 1.3068\n",
      "Epoch 12/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7429 - loss: 0.6903 - val_accuracy: 0.6192 - val_loss: 1.3605\n",
      "Epoch 13/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7602 - loss: 0.6614 - val_accuracy: 0.6192 - val_loss: 1.3154\n",
      "Epoch 14/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7535 - loss: 0.6548 - val_accuracy: 0.6324 - val_loss: 1.3267\n",
      "Epoch 15/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7687 - loss: 0.6250 - val_accuracy: 0.6306 - val_loss: 1.3172\n",
      "Epoch 16/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7723 - loss: 0.6105 - val_accuracy: 0.6473 - val_loss: 1.3430\n",
      "Epoch 17/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7772 - loss: 0.5885 - val_accuracy: 0.6456 - val_loss: 1.3345\n",
      "Epoch 18/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7954 - loss: 0.5537 - val_accuracy: 0.6473 - val_loss: 1.3003\n",
      "Epoch 19/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7972 - loss: 0.5275 - val_accuracy: 0.6403 - val_loss: 1.3329\n",
      "Epoch 20/20\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7935 - loss: 0.5562 - val_accuracy: 0.6332 - val_loss: 1.3133\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Test MAE: 0.8146\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
    "model.add(Dense(32, activation='relu'))  # Hidden layer\n",
    "model.add(Dense(10, activation='softmax'))  # Output layer for 10 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.1)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Test MAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refine (RNAseq)\n",
    "\n",
    "#### MAE of arcsin with scaler:\n",
    "#### MAE of arcsin without scaler:\n",
    "#### MAE of raw with scaler: 0.8146\n",
    "#### MAE of raw without scaler:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is regular MLP across each age bin??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davydsadovskyy/krishnanLab/age_sex_proteomic_model/venv_ordinal_neural_network/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Test MAE for fold 1: 0.8906\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davydsadovskyy/krishnanLab/age_sex_proteomic_model/venv_ordinal_neural_network/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Test MAE for fold 2: 0.9835\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davydsadovskyy/krishnanLab/age_sex_proteomic_model/venv_ordinal_neural_network/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Test MAE for fold 3: 0.8398\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davydsadovskyy/krishnanLab/age_sex_proteomic_model/venv_ordinal_neural_network/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Test MAE for fold 4: 0.8969\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davydsadovskyy/krishnanLab/age_sex_proteomic_model/venv_ordinal_neural_network/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Test MAE for fold 5: 0.8874\n",
      "Overall MAE across 5 folds: 0.8996\n",
      "MAE for age_bin_label 0: 1.2373\n",
      "MAE for age_bin_label 1: 0.6895\n",
      "MAE for age_bin_label 2: 0.6521\n",
      "MAE for age_bin_label 3: 0.6078\n",
      "MAE for age_bin_label 4: 0.8575\n",
      "MAE for age_bin_label 5: 1.0370\n",
      "MAE for age_bin_label 6: 0.8384\n",
      "MAE for age_bin_label 7: 0.9588\n",
      "MAE for age_bin_label 8: 1.2573\n",
      "MAE for age_bin_label 9: 1.4555\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize accumulators for MAE\n",
    "overall_mae_sum = 0\n",
    "fold_mae_per_label = {label: 0 for label in np.unique(labels)}\n",
    "count_per_label = {label: 0 for label in np.unique(labels)}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(refine2, labels)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    # Create train and test sets\n",
    "    X_train, X_test = refine2[train_idx], refine2[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))  # Output layer for 10 age bins\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.1, verbose=0)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Calculate overall MAE for this fold\n",
    "    fold_mae = mean_absolute_error(y_test, y_pred)\n",
    "    overall_mae_sum += fold_mae\n",
    "    print(f'Test MAE for fold {fold + 1}: {fold_mae:.4f}')\n",
    "\n",
    "    # Calculate MAE per age group (age_bin_label) for this fold\n",
    "    for label in np.unique(y_test):\n",
    "        label_indices = np.where(y_test == label)\n",
    "        label_mae = mean_absolute_error(y_test[label_indices], y_pred[label_indices])\n",
    "        fold_mae_per_label[label] += label_mae * len(label_indices[0])\n",
    "        count_per_label[label] += len(label_indices[0])\n",
    "\n",
    "# Calculate overall MAE across all folds\n",
    "overall_mae = overall_mae_sum / 5\n",
    "print(f'Overall MAE across 5 folds: {overall_mae:.4f}')\n",
    "\n",
    "# Calculate MAE per age group across all folds\n",
    "mae_per_label = {label: fold_mae_per_label[label] / count_per_label[label] if count_per_label[label] > 0 else 0 for label in fold_mae_per_label}\n",
    "\n",
    "# Print MAE per age group\n",
    "for label, mae in mae_per_label.items():\n",
    "    print(f'MAE for age_bin_label {label}: {mae:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and Plot the Overall and age-bin-wise MAE for CORN and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Fold CV - Ordinal Neural Network (CORN) vs MLP\n",
      "  Age Bin Label  Count  CORN MAE   MLP MAE\n",
      "0         [0–2]   1243    1.0829  1.237329\n",
      "1         (2–8]    760    0.7539  0.689474\n",
      "2        (8–12]   1098    0.6630  0.652095\n",
      "3       (12–20]   2157    0.5614  0.607789\n",
      "4       (20–35]   1867    0.7568  0.857525\n",
      "5       (35–45]   1404    0.6282  1.037037\n",
      "6       (45–60]   2711    0.4921  0.838436\n",
      "7       (60–70]   1554    0.7117  0.958816\n",
      "8       (70–80]    929    1.0032  1.257266\n",
      "9          > 80    483    1.0414  1.455487\n",
      "\n",
      "Overall MAE Comparison:\n",
      "  Model  Overall MAE\n",
      "0  CORN     0.711673\n",
      "1   MLP     0.899621\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CORN results from previous output (manually extracted)\n",
    "corn_mae_per_label = {\n",
    "    0: 1.0829,\n",
    "    1: 0.7539,\n",
    "    2: 0.6630,\n",
    "    3: 0.5614,\n",
    "    4: 0.7568,\n",
    "    5: 0.6282,\n",
    "    6: 0.4921,\n",
    "    7: 0.7117,\n",
    "    8: 1.0032,\n",
    "    9: 1.0414\n",
    "}\n",
    "\n",
    "# Calculate CORN MAE by averaging across each fold\n",
    "fold_data = joblib.load('fold_data.pkl')\n",
    "corn_overall_mae = sum(fold_data['mae']) / len(fold_data['mae'])\n",
    "\n",
    "# Data for MLP is already stored in overall_mae and mae_per_label from the MLP code\n",
    "\n",
    "# Get value counts for each age bin directly from refine_labels2['age_bin'].value_counts()\n",
    "age_bin_counts = refine_labels2['age_bin'].value_counts()\n",
    "\n",
    "# Sort the counts by the integer labels (from refine_labels2['age_bin_label'])\n",
    "sorted_bins = refine_labels2.groupby('age_bin_label')['age_bin'].first().sort_index()\n",
    "sorted_bin_counts = refine_labels2['age_bin_label'].value_counts().sort_index()\n",
    "\n",
    "# Combine CORN and MLP results into a single table, sorted by the smallest to largest age bin\n",
    "comparison_data = {\n",
    "    'Age Bin Label': sorted_bins.values,  # Sorted age bin labels\n",
    "    'Count': sorted_bin_counts.values,  # Sorted counts for each bin\n",
    "    'CORN MAE': [corn_mae_per_label[i] for i in range(10)],  # Sorted CORN MAE\n",
    "    'MLP MAE': [mae_per_label[i] for i in range(10)]  # Sorted MLP MAE\n",
    "}\n",
    "\n",
    "# Create the comparison DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Add overall MAE to the table\n",
    "overall_comparison_df = pd.DataFrame({\n",
    "    'Model': ['CORN', 'MLP'],\n",
    "    'Overall MAE': [corn_overall_mae, overall_mae]\n",
    "})\n",
    "\n",
    "# Display the detailed per-label MAE comparison with counts, sorted by age bin\n",
    "print(\"5 Fold CV - Ordinal Neural Network (CORN) vs MLP\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Display the overall MAE comparison\n",
    "print(\"\\nOverall MAE Comparison:\")\n",
    "print(overall_comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### averaging the per age bin MAE is not the same as averaging the MAE across 5 folds, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76946\n",
      "0.9591252898733315\n"
     ]
    }
   ],
   "source": [
    "print(sum([corn_mae_per_label[i] for i in range(10)])/10)\n",
    "print(sum([mae_per_label[i] for i in range(10)])/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05778700000000003\n",
      "0.05950428987333145\n"
     ]
    }
   ],
   "source": [
    "print(sum([corn_mae_per_label[i] for i in range(10)])/10 - 0.711673)\n",
    "print(sum([mae_per_label[i] for i in range(10)])/10 - .899621)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ordinal_neural_network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
